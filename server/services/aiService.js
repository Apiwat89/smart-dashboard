// server/services/aiService.js
const OpenAI = require("openai"); // üü¢ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Library
const db = require('../database/database'); 
const { v4: uuidv4 } = require('uuid'); 
require('dotenv').config();

// üü¢ Config OpenAI
const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY, 
});

// ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Model (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ gpt-4o ‡∏´‡∏£‡∏∑‡∏≠ gpt-3.5-turbo)
const MODEL_NAME = "gpt-5.2"; 

// üõ†Ô∏è _insertLog (Database ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° 100% ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ SQL)
function _insertLog(data) {
    const sql = `
        INSERT INTO ai_logs 
        (request_id, page_name, action_type, language, input_context, ai_response, input_tokens, output_tokens, total_tokens, saved_tokens, processing_time_ms, saved_time_ms, is_cached)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `;
    
    const params = [
        data.reqId || 'unknown',
        data.page || 'unknown',
        data.action || 'general',
        data.lang || 'TH',
        data.input || '',
        data.output || '',
        
        // ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ Token ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á
        data.input_tokens || 0,      
        data.output_tokens || 0,
        data.total_tokens || 0,
        
        data.savedTokens || 0,
        data.time || 0,
        data.savedTime || 0,
        data.isCached ? 1 : 0
    ];

    db.run(sql, params, (err) => {
        if (err) console.error("‚ùå Log Insert Error:", err.message);
    });
}

// ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏™‡πâ‡πÉ‡∏ô‡πÄ‡∏õ‡πá‡∏ô OpenAI)
async function generateAIResponse(userMessage, systemRole = "You are a helpful assistant.", logContext = {}) {
    const startTime = Date.now();
    const reqId = uuidv4();

    try {
        console.log(`Sending to OpenAI (${MODEL_NAME}) [${logContext.action || 'General'}]...`);

        // üü¢ 1. ‡∏à‡∏±‡∏î Format ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ö‡∏ö OpenAI (System + User)
        const messages = [
            { role: "system", content: systemRole },
            { role: "user", content: userMessage }
        ];

        // üü¢ 2. ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API
        const completion = await openai.chat.completions.create({
            model: MODEL_NAME,
            messages: messages,
            temperature: 0.7, // ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå
        });

        // üü¢ 3. ‡πÅ‡∏Å‡∏∞‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        const responseText = completion.choices[0].message.content;

        // üü¢ 4. ‡πÅ‡∏Å‡∏∞ Token Usage (OpenAI ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å Google ‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢)
        const usage = completion.usage || {};
        const input_tokens = usage.prompt_tokens || 0;      // ‡∏Ç‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤
        const output_tokens = usage.completion_tokens || 0; // ‡∏Ç‡∏≤‡∏≠‡∏≠‡∏Å
        const total_tokens = usage.total_tokens || 0;       // ‡∏£‡∏ß‡∏°

        const duration = Date.now() - startTime;
        
        // ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô String ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô DB ‡πÉ‡∏´‡πâ‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°
        const inputLogCheck = `System: ${systemRole}\nUser: ${userMessage}`;

        // üü¢ 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Log
        _insertLog({
            reqId: reqId,
            page: logContext.pageId,
            action: logContext.action,
            lang: logContext.lang,
            input: inputLogCheck, 
            output: responseText,
            
            // ‡∏™‡πà‡∏á Token ‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡∏∞‡∏°‡∏≤‡πÑ‡∏î‡πâ‡∏•‡∏á DB
            input_tokens: input_tokens,       
            output_tokens: output_tokens, 
            total_tokens: total_tokens,         
            
            savedTokens: 0,
            time: duration,
            savedTime: 0,
            isCached: false
        });

        return { 
            text: responseText, 
            id: reqId, 
            usage: { 
                input_tokens: input_tokens,
                output_tokens: output_tokens,
                total_tokens: total_tokens 
            },
            input: inputLogCheck 
        };

    } catch (error) {
        console.error("‚ùå OpenAI Error:", error);
        
        // Log Error ‡∏•‡∏á DB
        _insertLog({
            reqId: reqId,
            page: logContext.pageId,
            action: logContext.action,
            lang: logContext.lang,
            input: userMessage,
            output: `Error: ${error.message}`,
            input_tokens: 0, output_tokens: 0, total_tokens: 0,
            savedTokens: 0, time: Date.now() - startTime, savedTime: 0, isCached: false
        });

        return {
            text: "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß",
            id: reqId,
            usage: { total_tokens: 0 },
            input: userMessage
        };
    }
}

// ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Cache (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏õ‡πä‡∏∞ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ)
function logCacheHit(data) {
    _insertLog({
        reqId: data.reqId,
        page: data.pageId,
        action: data.action || 'cache_view',
        lang: data.lang,
        input: data.input || 'Cached View',
        output: data.output || 'Displayed from Cache',
        
        input_tokens: data.inputToken, 
        output_tokens: data.outputToken,
        total_tokens: data.totalToken,
        
        savedTokens: data.savedTokens,
        time: 0,
        savedTime: data.savedTime || 0,
        isCached: true
    });
}

module.exports = { generateAIResponse, logCacheHit };